# Constitutional AI Readings

## Core Papers (Required)

### 1. Constitutional AI: Harmlessness from AI Feedback
- **Link:** https://arxiv.org/abs/2212.08073
- **Authors:** Bai et al. (Anthropic)
- **Year:** 2022
- **Difficulty:** 4/5
- **Time:** 2-3 hours
- **Why read:** The foundational paper. Non-negotiable.

**Key sections to focus on:**
- Section 2: Methods (understand the two-phase approach)
- Section 3: Results on harmlessness
- Appendix: The actual principles used

### 2. Collective Constitutional AI: Aligning a Language Model with Public Input
- **Link:** https://www.anthropic.com/research/collective-constitutional-ai-aligning-a-language-model-with-public-input
- **Authors:** Anthropic
- **Year:** 2023
- **Difficulty:** 3/5
- **Time:** 1 hour
- **Why read:** Shows democratic/participatory approach to AI alignment

**Key takeaways:**
- How Polis platform was used
- Where public opinion aligned with internal constitution
- Where it differed

### 3. RLHF Book Chapter on Constitutional AI
- **Link:** https://rlhfbook.com/c/13-cai
- **Author:** Nathan Lambert
- **Difficulty:** 3/5
- **Time:** 45 min
- **Why read:** Excellent contextual overview, compares to other methods

---

## Background Reading (Helpful Context)

### 4. Training a Helpful and Harmless Assistant
- **Link:** https://arxiv.org/abs/2204.05862
- **Authors:** Anthropic
- **Year:** 2022
- **Difficulty:** 4/5
- **Time:** 2 hours
- **Why read:** Precursor to CAI, establishes HH framework

### 5. Claude's Character
- **Link:** https://www.anthropic.com/research/claude-character
- **Difficulty:** 2/5
- **Time:** 30 min
- **Why read:** See how CAI manifests in the actual product

### 6. Anthropic's Core Views on AI Safety
- **Link:** https://www.anthropic.com/news/core-views-on-ai-safety
- **Difficulty:** 2/5
- **Time:** 20 min
- **Why read:** Understand the broader context of CAI

---

## Blog Posts & Explainers

### 7. Constitutional AI Explainer (Anthropic)
- **Link:** https://www.anthropic.com/research/constitutional-ai-harmlessness-from-ai-feedback
- **Difficulty:** 2/5
- **Time:** 15 min
- **Why read:** Accessible overview before the paper

### 8. AI Safety Newsletter Coverage
- Search for "Constitutional AI" coverage in AI safety newsletters
- **Difficulty:** 2/5
- **Time:** 30 min
- **Why read:** Get external perspectives

---

## Advanced (Optional)

### 9. Inverse Constitutional AI
- **Link:** https://arxiv.org/abs/2501.17112
- **Year:** 2025
- **Difficulty:** 5/5
- **Time:** 2 hours
- **Why read:** Cutting-edge extension of CAI

### 10. Red Teaming Language Models
- **Link:** https://arxiv.org/abs/2202.03286
- **Difficulty:** 4/5
- **Time:** 1.5 hours
- **Why read:** Understand how CAI models are evaluated

---

## Reading Order

1. Start with the Anthropic explainer (#7) - 15 min
2. Read the main CAI paper (#1) - focus on Sections 2-3 first
3. Read Collective CAI (#2) for the participatory angle
4. Nathan Lambert's chapter (#3) for context
5. Optionally: HH paper (#4) for historical context

---

## XP Values

| Reading | XP |
|---------|-----|
| CAI Paper (main) | +75 |
| Collective CAI | +50 |
| RLHF Book Chapter | +25 |
| Blog posts | +15 each |
| Advanced papers | +75 each |

**Module completion bonus:** +200 XP
